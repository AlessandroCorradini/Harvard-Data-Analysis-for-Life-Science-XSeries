---
title: "Homework 03 - Statistical Models"
author: "Alessandro Corradini - Harvard Data Science for Life Science XSeries"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Statistical Models Exercises

### Statistical Models Exercises #1

Suppose you have an urn with blue and red balls. If N balls at selected at random with replacement (you put the ball back after you pick it) we can denote the outcomes as random variables $\ X_1,\dots,X_N$ that are 1 or 0. If the proportion of red balls is p then the distribution of each of these is:

$\ \mbox{Pr}(X_i=1)=p$

These are also called Bernoulli trials. Note that these random variables are independent because we replace the balls. Flipping a coin is an example of this with p = 0.5.

You can show that the mean and variance are p and p(1-p) respectively. The binomial distribution gives us the distribution of the sum $\ S_N$ of these random variables. The probability that we see k red balls is given by:

$\ \mbox{Pr}(S_N=k) = {N \choose k} p^k (1-p)^{N-k}$

In R the function dbinom gives you this result. The function pbinom gives us $\ \mbox{Pr}(S_N\leq k)$.

This equation has many uses in the life sciences. We give some examples below.

The probability of conceiving a girl is 0.49. What is the probability that a family with 4 children has 2 girls and 2 boys (you can assume no twins)?

```{r}
dbinom(2,4,0.49)
```

### Statistical Models Exercises #2

Use what you learned in Question #1 to answer these questions:

What is the probability that a family with 10 children has 4 girls and 6 boys (you can assume no twins)?

```{r}
dbinom(4,10,0.49)
```

### Statistical Models Exercises #3

The genome has 3 billion bases. About 20% are C, 20% are G, 30% are T and 30% are A. Suppose you take a random interval of 20 bases, what is the probability that the GC-content (proportion of Gs or Cs) is strictly above 0.5 in this interval (you can assume independence)?

```{r}
1-pbinom(10,20,0.4)
```

### Statistical Models Exercises #4

The following two questions are motivated by this event.

The probability of winning the lottery is 1 in 175,223,510. If 189,000,000 randomly generated (with replacement) tickets are sold, what is the probability that at least one winning tickets is sold? (give your answer as a proportion not percentage)

```{r}
1 - dbinom(0, 189000000, 1/175223510)
```

### Statistical Models Exercises #5

Using the information from the previous question, what is the probability that two or more winning tickets are sold?

```{r}
1 - pbinom(1, 189000000, 1/175223510)
```

### Statistical Models Exercises #6 (Normal approximation)

We can show that the binomial distribution is approximately normal with N is large and p is not too close to 0 or 1. This means that

$\ \frac{S_N - \mbox{E}(S_N)}{ \sqrt{ \mbox{Var}(S_N)}}$

is approximately normal with mean 0 and SD 1. Using the results for sums of independent random variables we learned in a previous course, we can show that \mbox{E}(S_N) = Np and \mbox{Var}(S_n)=Np(1-p).

The genome has 3 billion bases. About 20% are C, 20% are G, 30% are T and 30% are A. Suppose you take a random interval of 20 bases, what is the exact probability that the GC-content (proportion of Gs of Cs) is greater than 0.35 and smaller or equal to 0.45 in this interval? HINT: use the binomial distribution.

```{r}
pbinom(9,20,0.4)-pbinom(7,20,0.4)
```

### Statistical Models Exercises #7

For the question above, what is the normal approximation to the probability?

```{r}
b <- (9 - 20*.4)/sqrt(20*.4*.6)
a <- (7 - 20*.4)/sqrt(20*.4*.6)
pnorm(b)-pnorm(a)
```

### Statistical Models Exercises #8

Repeat Statistical Models Exercises #3, but using an interval of 1000 bases. What is the difference (in absolute value) between the normal approximation and the exact probability (using binomial) of the GC-content being greater than 0.35 and lesser or equal to 0.45?

```{r}
exact = pbinom(450,1000,0.4)-pbinom(350,1000,0.4)
b <- (450 - 1000*.4)/sqrt(1000*.4*.6)
a <- (350 - 1000*.4)/sqrt(1000*.4*.6)
approx <- pnorm(b)-pnorm(a)
abs(exact-approx)
```

### Statistical Models Exercises #9

The Cs in our genomes can be methylated or unmethylated. Suppose we have a large (millions) group of cells in which a proportion  of a C of interest are methylated. We break up the DNA of these cells and randomly select pieces and end up with  pieces that contain the C we care about. This means that the probability of seeing  methylated Cs is binomial:

```
exact = dbinom(k,N,p)
```

We can approximate this with the normal distribution:

```
a <- (k+0.5 - N*p)/sqrt(N*p*(1-p))
b <- (k-0.5 - N*p)/sqrt(N*p*(1-p))
approx = pnorm(a) - pnorm(b)
```

Let

```{r}
Ns <- c(5,10,30,100)
ps <- c(0.01,0.10,0.5,0.9,0.99)
```

Compare the normal approximation and exact probability (from binomial) of the proportion of Cs being K = 1,...,N-1. Plot the exact versus approximate probability for each p and N combination

Study the plots and tell us which of the following is NOT true.

```{r}
Ns <- c(5,10,30,100)
ps <- c(0.01,0.10,0.5,0.9,0.99)
library(rafalib)
mypar(4,5)
for(N in Ns){
  ks <- 1:(N-1)
  for(p in ps){
    exact = dbinom(ks,N,p)
    a = (ks+0.5 - N*p)/sqrt(N*p*(1-p))
    b = (ks-0.5 - N*p)/sqrt(N*p*(1-p))
    approx = pnorm(a) - pnorm(b)
    LIM <- range(c(approx,exact))
    plot(exact,approx,main=paste("N =",N," p = ",p),xlim=LIM,ylim=LIM,col=1,pch=16)
    abline(0,1)
  }
}
```

- The normal approximation works well when p is close to 0.5 even for small N = 10.
- The normal approximation breaks down when p is close to 0 or 1 even for large N.
- **When N is 100 all approximations are spot on.**
- When p = 0.01 the approximation are terrible for N = 5,10,30  and only OK for n = 100.

### Statistical Models Exercises #10 (Poisson approximation)

We saw in the previous question that when p is very small, the normal approximation breaks down. If N is very large, then we can use the Poisson approximation.

Earlier we computed the probability of 2 or more tickets winning the lottery when the odds of winning were 1 in 175,223,510 and 189,000,000 tickets were sold. Using the binomial we can run the code below to compute the probability of exactly two people winning to be:

```{r}
N <- 189000000
p <- 1/175223510
dbinom(2,N,p)
```

If we were to use the normal approximation, we would overestimate this as you can see by running this code:

```{r}
a <- (2+0.5 - N*p)/sqrt(N*p*(1-p))
b <- (2-0.5 - N*p)/sqrt(N*p*(1-p))
pnorm(a) - pnorm(b)
```

To use the Poisson approximation here use the rate $\ \lambda= Np$ representing the number of tickets per 189,000,000 that win the lottery. Run the following code and note how much better the approximation is:

```{r}
dpois(2,N*p)
```

In this case it is practically the same because N is very very large and Np is not 0. These are the assumptions needed for the Poisson to work.

What is the Poisson approximation for the probability of two or more person winning?

```{r}
N = 189000000
p = 1/175223510
1 - ppois(1, N*p)
```

## MLE Exercises

### MLE Exercises #1

In this assessment we are going to try to answer the question: is there a section of the human cytomegalovirus genome in which the rate of palindromes is higher than expected?

Make sure you have the latest version of the dagdata library:

```{r}
library(devtools)
install_github("genomicsclass/dagdata")
```

and then load the palindrome data from the Human cytomegalovirus genome:

```{r}
library(dagdata)
data(hcmv)
```

These are the locations of palindromes on the genome of this virus:

```{r}
library(rafalib)
mypar()
plot(locations,rep(1,length(locations)),ylab="",yaxt="n")
```

These palindromes are quite rare, p is very small. If we break the genome into bins of 4000 basepairs, then we have Np not so small and we might be able to use Poisson to model the number of palindromes in each bin:

```{r}
breaks=seq(0,4000*round(max(locations)/4000),4000)
tmp=cut(locations,breaks)
counts=as.numeric(table(tmp))
```

So if our model is correct counts should follow a Poisson distribution. The distribution seems about right:

```{r}
hist(counts)
```

Let $\ X_1,\dots,X_n$ be the random variables representing counts then $\ \Pr(X_i=k)= \lambda^k / k!\exp(-\lambda)$

So to fully describe this distribution we need . For this we will use MLE.

To compute the Maximum Likelihood Estimate (MLE) we ask what is the probability of observing our data (which we denote with small caps) for a given $\ \lambda$:

$\ L(\lambda) = \mbox{Pr}(X_1=x_1 \mbox{ and } X_2=x2 \mbox{ and } \dots X_n=x_n; \lambda)$

We assume that the X are independent, thus the probabilities multiply:

$\ L(\lambda)=\mbox{Pr}(X_1=x_1) \times \mbox{Pr}(X_2=x2) \times \dots \times \mbox{Pr}(X_n=x_n)$

Now we can write it in R. For example for $\ \lambda=4$ we have:

```{r}
probs <- dpois(counts,4)
likelihood <- prod(probs)
likelihood
```

Run the code above to note that this is a tiny number. It is usually more convenient to compute log-likelihoods

```{r}
logprobs <- dpois(counts,4,log=TRUE)
loglikelihood <- sum(logprobs)
loglikelihood
```

Now write a function that takes $\ \lambda$ and the vector of counts as input, and returns the log-likelihood. Compute this log-likelihood for lambdas = seq(0,15,len=300) and make a plot.

What value of lambdas maximizes the log-likelihood?

```{r}
loglikelihood = function(lambda,x){
  sum(dpois(x,lambda,log=TRUE))
}
lambdas = seq(1,15,len=300)
l = sapply(lambdas,function(lambda) loglikelihood(lambda,counts))
plot(lambdas,l)
mle=lambdas[which.max(l)]
abline(v=mle)
print(mle)

mean(counts)
```

### MLE Exercises #2

The point of collecting this dataset was to try to determine if there is a region of the genome that has higher palindrome rate than expected. We can create a plot and see the counts per location:

```{r}
breaks=seq(0,4000*round(max(locations)/4000),4000)
tmp=cut(locations,breaks)
counts=as.numeric(table(tmp))
binLocation=(breaks[-1]+breaks[-length(breaks)])/2
plot(binLocation,counts,type="l",xlab=)
```

What is the center of the bin with the highest count?

```{r}
binLocation[which.max(counts)]
```

### MLE Exercises #3

For the question above, what is the maximum count?

```{r}
max(counts)
```

### MLE Exercises #4

Now that we have identified the location with the largest palindrome count, we want to know if by chance we could see a value this big.

If X is a Poisson random variable with rate

```{r}
lambda = mean(counts[ - which.max(counts) ])
```

What is the probability of seeing a count of 14 or more?

```{r}
pval = 1 - ppois(13,lambda)
print(pval)
```

### MLE Exercises #5

From the question above, we obtain a p-value smaller than 0.001 for a count of 14. Why is it problematic to report this p-value as strong evidence of a location that is different?

- Poisson in only an approximation.
- **We selected the highest region out of 57 and need to adjust for multiple testing.**
- $\ \lambda$ is an estimate, a random variable, and we didn't take into account its variability.
- We don't know the effect size.

### MLE Exercises #6

Use the Bonferroni correction to determine the p-value cut-off that guarantees a FWER of 0.05. What is this p-value cutoff?

```{r}
0.05/57
```

### MLE Exercises #7

Create a qq-plot to see if our Poisson model is a good fit:

```{r}
ps <- (seq(along=counts) - 0.5)/length(counts)
lambda <- mean( counts[ -which.max(counts)])
poisq <- qpois(ps,lambda)
qqplot(poisq,counts)
abline(0,1)
```

How would you characterize this qq-plot

- Poisson is a terrible approximation.
- **Poisson is a very good approximation except for one point that we actually think is associated with a region of interest.**
- There are too many 1s in the data.
- A normal distribution provides a better approximation.

## Models for Variance Exercises

Install and load the following data library:

```{r}
library(devtools)
install_github("genomicsclass/tissuesGeneExpression")
library(tissuesGeneExpression)
```

Now load this data and select the columns related to endometrium: 

```{r}
data("tissuesGeneExpression")
library(genefilter)
y = e[,which(tissue=="endometrium")]
```

This will give you a matrix y with 15 samples.

### Models for Variance Exercises #1

Compute the across sample variance for the fifteen samples. Then make a qq-plot to see if the variances follow ae normal distribution.

Which statement is true? (pick one)

```{r}
library(genefilter)
s2 <- rowVars(y)
library(rafalib)
mypar(1,2)
qqnorm(s2)
qqline(s2)
##To see the square root transformation does not help much:
qqnorm(sqrt(s2))
qqline(sqrt(s2))
```

- With the exception of a handful of outliers, the data follow a normal distribution.
- The variance does not follow a normal distribution, but taking the square root fixes this.
- **The normal distribution is not a useful approximation here: the left tail is over estimated and the right tail is underestimated.**
- The normal distribution fits the data almost perfectly.

### Models for Variance Exercises #2

Now fit an F-distribution with 14 degrees of freedom using the fitFDist function in the limma package:

What is estimated the estimated scale parameter?

```{r}
library(limma)
estimates=fitFDist(s2,14)
print( estimates$scale )
```

### Models for Variance Exercises #3

Now create a qq-plot of the observed sample standard deviation versus the quantiles predicted by the F-distribution (remember to take square root).

Which of the following best describes the qq-plot?

```{r}
ps <- (seq(along=s2)-0.5)/length(s2)
theoretical<- qf(ps,14,estimates$df2)*estimates$scale 
LIM <- sqrt( range(c(theoretical,s2)) )
mypar(1,2)
qqplot(sqrt( theoretical ), sqrt( s2 ),ylim=LIM,xlim=LIM)
abline(0,1)
##close up excluding the upper 5%
K <- sqrt( quantile(s2,0.95) )
qqplot( sqrt( theoretical ), sqrt( s2 ),ylim=c(0,K),xlim=c(0,K))
abline(0,1)
```

- The fitted F-distribution provides a perfect fit.
- **If we exclude the genes with the highest variances (top 5%), the F-distribution provides a good fit.**
- If we exclude the genes with the lowest variances (bottom 5%), the F-distribution provides a good fit.
- The normal distribution provided a better fit.